{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4920883",
   "metadata": {},
   "source": [
    "###  모델 프리징 (Model Freezing)\n",
    "\n",
    "전이 학습 중 잘 학습 된 모델을 가져와 원하는 연구에 사용할 수 있다. 데이터가 유사한 경우에는 추가적으로 전체 학습 없이도 좋은 성능이 나올 수 있다. 따라서 피쳐 추출에 해당하는 합성곱 층의 변수를 업데이트 하지 않고 분류 파트에 해당하는 fully connected layer의 변수만 업데이트 할 수 있는데 이 때 변수가 없데이트 되지 않게 변수를 얼린다고 하여 이를 프리징(Freezing)이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5052803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import trange "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb15b1",
   "metadata": {},
   "source": [
    "#### 1. GPU 연산 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8378c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps is available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"{device} is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ceffe2",
   "metadata": {},
   "source": [
    "#### 2. CIFAR10 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ce8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 및 전처리 작업\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomCrop(32, padding=4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True) \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5969ba4",
   "metadata": {},
   "source": [
    "#### 3. Pretrained model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2aa261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ResNet-18 불러오기\n",
    "# weights='DEFAULT' : ResNet-18 구조를 쓰되, ImageNet으로 이미 똑똑해진 모델을 불러온다.\n",
    "# weights=False를 하면 ResNet18 구조만 불러온다.\n",
    "# 모델과 텐서에 .to(device)를 붙여야만 GPU 연산이 가능하다.\n",
    "\n",
    "model = torchvision.models.resnet18(weights='DEFAULT')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85653c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) # feature map의 크기가 유지된다.\n",
    "model.fc = nn.Linear(512, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35445ad",
   "metadata": {},
   "source": [
    "#### 4. 모델 프리징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8825a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight\n",
      "1 bn1.weight\n",
      "2 bn1.bias\n",
      "3 layer1.0.conv1.weight\n",
      "4 layer1.0.bn1.weight\n",
      "5 layer1.0.bn1.bias\n",
      "6 layer1.0.conv2.weight\n",
      "7 layer1.0.bn2.weight\n",
      "8 layer1.0.bn2.bias\n",
      "9 layer1.1.conv1.weight\n",
      "10 layer1.1.bn1.weight\n",
      "11 layer1.1.bn1.bias\n",
      "12 layer1.1.conv2.weight\n",
      "13 layer1.1.bn2.weight\n",
      "14 layer1.1.bn2.bias\n",
      "15 layer2.0.conv1.weight\n",
      "16 layer2.0.bn1.weight\n",
      "17 layer2.0.bn1.bias\n",
      "18 layer2.0.conv2.weight\n",
      "19 layer2.0.bn2.weight\n",
      "20 layer2.0.bn2.bias\n",
      "21 layer2.0.downsample.0.weight\n",
      "22 layer2.0.downsample.1.weight\n",
      "23 layer2.0.downsample.1.bias\n",
      "24 layer2.1.conv1.weight\n",
      "25 layer2.1.bn1.weight\n",
      "26 layer2.1.bn1.bias\n",
      "27 layer2.1.conv2.weight\n",
      "28 layer2.1.bn2.weight\n",
      "29 layer2.1.bn2.bias\n",
      "30 layer3.0.conv1.weight\n",
      "31 layer3.0.bn1.weight\n",
      "32 layer3.0.bn1.bias\n",
      "33 layer3.0.conv2.weight\n",
      "34 layer3.0.bn2.weight\n",
      "35 layer3.0.bn2.bias\n",
      "36 layer3.0.downsample.0.weight\n",
      "37 layer3.0.downsample.1.weight\n",
      "38 layer3.0.downsample.1.bias\n",
      "39 layer3.1.conv1.weight\n",
      "40 layer3.1.bn1.weight\n",
      "41 layer3.1.bn1.bias\n",
      "42 layer3.1.conv2.weight\n",
      "43 layer3.1.bn2.weight\n",
      "44 layer3.1.bn2.bias\n",
      "45 layer4.0.conv1.weight\n",
      "46 layer4.0.bn1.weight\n",
      "47 layer4.0.bn1.bias\n",
      "48 layer4.0.conv2.weight\n",
      "49 layer4.0.bn2.weight\n",
      "50 layer4.0.bn2.bias\n",
      "51 layer4.0.downsample.0.weight\n",
      "52 layer4.0.downsample.1.weight\n",
      "53 layer4.0.downsample.1.bias\n",
      "54 layer4.1.conv1.weight\n",
      "55 layer4.1.bn1.weight\n",
      "56 layer4.1.bn1.bias\n",
      "57 layer4.1.conv2.weight\n",
      "58 layer4.1.bn2.weight\n",
      "59 layer4.1.bn2.bias\n",
      "60 fc.weight\n",
      "61 fc.bias\n"
     ]
    }
   ],
   "source": [
    "# 파라메타 번호 확인 하기\n",
    "# 각 층은 보통 2가지 파라미터를 가진다.\n",
    "# 1. weight(가중치)\n",
    "# 2. bias(편향, 옵션)\n",
    "i = 0\n",
    "\n",
    "for name, param in model.named_parameters(): # 모델안의 학습 가능한 가중치와 편향을 하나하나 가져온다. -> 결과를 보면 모두 각각의 층의 weight와 bias인 것을 알 수 있다.\n",
    "  print(i,name)\n",
    "\n",
    "  i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27322a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozen이라는 범위를 만들어 (3부터 시작해서 3씩 증가하며 60 미만까지 숫자를 생성한다.)\n",
    "# 해당 범위의 숫자는 특정 파라미터 번호를 의미하며, 이 번호에 해당하는 파라미터들은 학습하지 않고 고정된다.\n",
    "frozen = range(3,60,3)\n",
    "\n",
    "for i, (name, param) in enumerate(model.named_parameters()):\n",
    "    \n",
    "    if i in frozen:\n",
    "        param.requires_grad = False # 학습할 때 업데이트 되지 않는다. ~ gradient가 계산되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b4e1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# requires_grad 확인\n",
    "print(model.layer4[1].conv2.weight.requires_grad)\n",
    "print(model.fc.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f507c",
   "metadata": {},
   "source": [
    "#### 5. 손실함수와 최적화 방법 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7851a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 분류 문제에서 자주 쓰이는 손실 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a36f96",
   "metadata": {},
   "source": [
    "#### 6. 손실함수와 최적화 방법 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a830e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "ls = 2 # 어지간한 loss는 2보다 작다.\n",
    "pbar = trange(num_epochs)\n",
    "\n",
    "for epoch in pbar:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "          \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.detach(), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    cost = running_loss / len(trainloader)   \n",
    "    acc = 100*correct / total\n",
    "\n",
    "    if cost < ls:\n",
    "        ls = cost\n",
    "        torch.save(model.state_dict(), './models/cifar10_resnet_frozen.pth')   \n",
    "\n",
    "    pbar.set_postfix({'loss' : cost, 'train acc' : acc}) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b7815",
   "metadata": {},
   "source": [
    "#### 7. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./models/cifar10_resnet_frozen.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total)) \n",
    "\n",
    "# 모델 프리징 미적용시: 학습 27분 소요, 정확도 85%\n",
    "# 모델 프리징 적용시: 학습 21분 소요, 정확도 82%\n",
    "# 빠르지만 성능은 조금 손해 볼 수 있다는 결과가 나왔다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
