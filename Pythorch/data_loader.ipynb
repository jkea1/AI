{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기\n",
    "딥러닝을 포함한 머신러닝의 근원은 데이터다.\n",
    "\n",
    "따라서 데이터의 수집, 가공, 사용 방법에 따라 모델 성능이 크게 달라질 수 있으며 데이터의 형태는 매우 다양하기 때문에 데이터를 잘 불러오는 것은 가장 중요힌 단계 중 하나다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision # 이미지 관련 된 파이토치 라이브러리\n",
    "import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리\n",
    "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
    "import numpy as np # 넘파이 기본 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 파이토치 제공 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr.Compose 내에 원하는 전처리를 차례대로 넣어주면 된다.\n",
    "transf = tr.Compose([tr.Resize(16), tr.ToTensor()]) # 16 x 16으로 이미지 크기 변환 후 텐서 형태 타입으로 변환한다. tr.Resize((16, 16))\n",
    "\n",
    "# 텐서 형태뿐만 아니라 여러가지 형태로 변환할 수 있다.\n",
    "# Transforms on PIL Image\n",
    "# Pad(패드를 씌워준다.), Grayscale(0~1 사이 값으로 만들어준다.), RandomCrop(이미지 일부를 랜덤하게 잘라준다.), Normalize(정규화 해준다.) ..\n",
    "# Transforms on Torch. * Tensor - tensor image\n",
    "# torchvision.transforms.ToPILImage(mode=None)...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf) # CIFAR10 데이터셋을 다운로드하고 전처리한다.\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf) # CIFAR10 데이터셋을 다운로드하고 전처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# 일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플(tuple) 형태다. (이미지, 라벨)\n",
    "# train_set[0]은 학습 데이터의 첫 번째 데이터로 이미지 한 장과 라벨 숫자 하나가 저장되어 있다.\n",
    "# 즉, train_set[0][0]은 이미지, train_set[0][1]은 라벨이다.\n",
    "\n",
    "print(train_set[0][0].size())\n",
    "\n",
    "# 현재 이미지 사이즈는 3x16x16이다. 여기서 3은 채널 수를 말하고 16x16은 이미지의 너비와 높이를 의미한다.\n",
    "# CIFAR10와 같은 일반적인 컬러 사진 데이터셋은 3채널(RGB(Y))로 이루어져 있다. 그리고 (높이)x(너비)x(채널 수)로 크기가 표현된다.\n",
    "# 하지만 파이토치에서는 (채널 수)x(높이)x(너비)로 크기가 표현된다. 즉, (3)x(16)x(16)이다.\n",
    "# 따라서 3x16x16은 3채널의 16x16 크기의 이미지라는 의미다.\n",
    "# train_set[0][0].size()는 torch.Size([3, 16, 16]) 형태로 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝을 할 때 데이터를 모델에 넣기 위해서는 데이터셋을 정리해 주어야 한다.\n",
    "# (그래서 gradient descent를 사용하지 않고 stochastic gradient descent를 사용한다.)\n",
    "# 데이터셋을 정리해 주는 역할을 하는 것이 DataLoader이다.\n",
    "# DataLoader는 데이터셋을 미니 배치 형태의 단위로 나누어 주고, 데이터를 섞어 주는 역할을 한다.\n",
    "# 따라서 배치 사이즈 및 셔플 여부 등을 선택 할 수 있다.\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=50, shuffle=True) # 배치 사이즈 4로 설정\n",
    "test_loader = DataLoader(test_set, batch_size=50, shuffle=False) # 배치 사이즈 4로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)\n",
    "\n",
    "# CIFAR10 데이터셋은 총 50,000개의 학습 데이터로 이루어져 있다.\n",
    "# 배치 사이즈가 50장 이라면 50,000/50 = 1,000이므로 1,000개의 배치로 나누어 진다.\n",
    "# 즉 train_loader는 잘 만들어졌다는 것을 단편적으로 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# iter(), next()를 이용해 일부 데이터를 확인 할 수 있다.\n",
    "# iter() -> 이터러블(iterable) 객체를 반복자(iterator) 객체로 변환해 주는 함수. \n",
    "# 1. Iterable(이터러블)\n",
    "# for 루프로 순회할 수 있는 객체 (ex. 리스트, 튜플, 딕셔너리, 문자열, DataLoader 등)를 반복자(iterator)로 변환해준다.\n",
    "# 2. Iterator(이터레이터)\n",
    "# __next__() 메서드를 이용해서 하나씩 값을 꺼낼 수 있는 객체 -> next() 함수를 사용할 수 있다.\n",
    "# label -> 각 이미지가 어떤 부류인지 나타내는 정보\n",
    "data_iter = iter(train_loader) # train_loader를 이터레이터 형태로 변환한다.\n",
    "images, labels = next(data_iter) # 이터레이터에서 다음 값을 가져온다.\n",
    "\n",
    "print(images.size()) # 이미지 사이즈\n",
    "\n",
    "# 일반적으로 학습 데이터는 4차원 텐서 형태로 모델에서 사용된다.\n",
    "# (배치 사이즈)x(채널 수)x(높이)x(너비) 형태로 되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 같은 클래스 별로 폴더를 정리한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 같은 클래스 별로 미리 폴더를 정리 된 경우, ImageFolder의 1줄 선언으로 개인 데이터를 사용할 수 있다.\n",
    "# 별도의 라벨링이 필요 없으며, 폴더 별로 자동으로 라벨링이 된다.\n",
    "# 예를 들어, class 폴더에 tiger, lion, bear 폴더 (./class/tiger 와 ./class/lion)를 미리 만든다.\n",
    "# 다음으로 ImageFolder에 상위 폴더 ./class를 입력하면 이미지와 라벨이 정리 되어 데이터를 불러온다.\n",
    "\n",
    "transf = tr.Compose([tr.Resize((128, 128)), tr.ToTensor()]) # 128x128로 크기 변환 후 텐서 형태 타입으로 변환한다.\n",
    "train_set = torchvision.datasets.ImageFolder(root='./class', transform=transf) # 커스텀 데이터를 불러온다.\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True) # 데이터를 미니 배치 사이즈 4 크기로 만들어 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader) # train_loader를 반복자 형태로 변환한다.\n",
    "images, labels = next(data_iter) # 반복자에서 다음 값을 가져온다.\n",
    "\n",
    "print(images.size(), labels) # 이미지 사이즈\n",
    "# torch.Size([2, 3, 128, 128]) tensor([0, 1]) -> 0, 1 을 보아하니 아마 tiger, lion 폴더에 있는 이미지가 랜덤하게 섞여서 들어온 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 정형화 되지 않은 커스텀 데이터 불러오기 (2. 를 사용할 수 없는 경우)\n",
    "1) 라벨 별로 폴더 정리가 되어 있지 않은 경우\n",
    "2) 다른 작업들과 공유 된 데이터인 경우 폴더를 함부로 정리 할 수 없다.\n",
    "3) 이미지 데이터라도 이미지가 아닌 텍스트, 리스트, 배열 등으로 저장 되어 있는 경우도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32, 3) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정한다.\n",
    "\n",
    "train_images = np.random.randint(256, size=(100, 32, 32, 3)) # (이미지 수)x(높이)x(너비)x(채널 수)\n",
    "train_labels = np.random.randint(2, size=(100, 1)) # 라벨 수\n",
    "\n",
    "# 이미지 전처리 작업이 필요한 경우 openCV와 같은 라이브러리를 이용하여 이 곳에서 작업 할 수 도 있다.\n",
    "# 사람마다 다르지만 이 단계에서 전처리를 하는 것을 추천한다.\n",
    "# 전처리 후에 데이터셋을 만들고, DataLoader를 이용하여 배치 사이즈를 설정한다.\n",
    "# 그 이유는 torchvision.transforms 라이브러리 보다\n",
    "# OpenCV, SciPy와 같은 라이브러리가 더 많은 전처리 기술을 제공하며 \n",
    "# 이미지를 미리 처리해 놓고 전치리 된 이미지를 살펴보면서 작업 하는 것을 추천하기 때문이다.\n",
    "# 또한, OpenCV는 GPU를 사용하지 않기 때문에 CPU에서 작업을 하게 된다.\n",
    "# 따라서 사용 목적과 편의성에 맞게 본인이 전처리를 어디서 할 지 정하면 될 것이다.\n",
    "\n",
    "# ...\n",
    "# ...\n",
    "# train_images, train_labels = preprocess(train_images, train_labels) # 전처리 함수\n",
    "# ...\n",
    "# ...\n",
    "\n",
    "print(train_images.shape, train_labels.shape) # (100, 32, 32, 3) (100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from torch.utils.data import Dateset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "  def __init__(self):\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "  \n",
    "  def __len__(self):\n",
    "\n",
    "이 양식을 통으로 가지고 다니자!!  \n",
    "'''\n",
    "\n",
    "class TensorData(Dataset):\n",
    "  def __init__(self, x_data, y_data): # 어떤 데이터를 불러 올 건지 사용자가 정의 할 수 있다.\n",
    "    self.x_data = torch.FloatTensor(x_data) # 이미지 데이터를 FloatTensor 형태로 변환한다.\n",
    "    self.x_data = self.x_data.permute(0, 3, 1, 2) # (이미지 수)x(높이)x(너비)x(채널 수) -> (배치 크기)x(채널 수)x(높이)x(너비) 형태로 변환한다.\n",
    "    self.y_data = torch.LongTensor(y_data) # 라벨 데이터를 LongTensor 형태로 변환한다.\n",
    "    self.len = self.y_data.shape[0] # 클래스 내의 들어온 데이터 개수\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return self.x_data[index], self.y_data[index] # 뽑아 낼 데이터를 적어준다.\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.len # 클래스 내의 들어 온 데이터 개수\n",
    "  \n",
    "  # 파이토치에서는 (배치 크기)x(채널 수)x(높이)x(너비) 데이터가 사용 되므로 원래 데이터 (이미지 수)x(높이)x(너비)x(채널 수)를 변경해야만 한다.\n",
    "  # permute 0(이미지 수), 1(높이), 2(너비), 3(채널 수)을 0(이미지 수), 3(채널 수), 1(높이), 2(너비)로 바꿔주는 것이기 때문이다.\n",
    "  # .permute(0, 3, 1, 2)을 사용하는 것이다. -> (이미지 수)x(채널 수)x(높이)x(너비) 형태로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorData(train_images, train_labels) # 텐서 데이터 불러오기\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True) # 미니 배치 형태로 데이터 갖추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "print(images.size(), labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 커스텀 데이터 + 커스텀 전처리\n",
    "\n",
    "텐서 생성 부분에서 이미지 전처리 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정한다.\n",
    "# 외부로부터 데이터를 불러오는 방식은 다양하다.\n",
    "# glob 라이브러리를 이용하면 -> 경로에 대한 내용을 받아서 PIL, openCV 등의 형태의 이미지 파일을 불러올 수 있다.\n",
    "train_images = np.random.randint(256, size=(100, 32, 32, 3)) # (이미지 수)x(높이)x(너비)x(채널 수)\n",
    "train_labels = np.random.randint(2, size=(100, 1)) # 라벨 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 에서 사용한 양식을 그대로 사용하되 전처리 작업을 할 수 있도록 transform을 추가한다.\n",
    "# 목적 = 텐서를 만들면서 transform을 하고 싶은거다.\n",
    "class MyDataset(Dataset):\n",
    "  def __init__(self, x_data, y_data, transform=None):\n",
    "    self.x_data = x_data # 넘파이 배열이 들어온다.\n",
    "    self.y_data = y_data # 넘파이 배열이 들어온다.\n",
    "    self.transform = transform\n",
    "    self.len = len(y_data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "    if self.transform:\n",
    "      sample = self.transform(sample) # self.transform이 None이 아니라면 전처리를 작업한다. transform을 하면서 넘파이 형태를 텐서로 만들어 준다.\n",
    "\n",
    "    return sample # 3. 과 다르게 넘파이 배열로 출력 되는 것에 유의하도록 한다.\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 기술 직접 만들어 보기\n",
    "# 위의 기본 양식과 같이 사용하기 위해 call 함수를 사용한다.\n",
    "# def __call__ 내의 원하는 전처리 작업을 프로그래밍 할 수 있다.\n",
    "\n",
    "# 1. 텐서 변환\n",
    "# __call__ : 객체가 함수처럼 호출될 수 있도록 만드는 역할\n",
    "class ToTensor: \n",
    "  def __call__(self, sample):\n",
    "    inputs, labels = sample # sample은 넘파이 배열 형태로 들어온다.\n",
    "    inputs = torch.FloatTensor(inputs) # 넘파이 배열을 FloatTensor 형태로 변환한다.\n",
    "    inputs = inputs.permute(2, 0, 1) # (채널 수)x(높이)x(너비) 형태로 변환한다.\n",
    "\n",
    "    return inputs, torch.LongTensor(labels) # 텐서로 변환\n",
    "\n",
    "# 2. 선형식\n",
    "class LinearTensor:\n",
    "  def __init__(self, slope=1, bias=0):\n",
    "    self.slope = slope\n",
    "    self.bias = bias\n",
    "  \n",
    "  def __call__(self, sample):\n",
    "    inputs, labels = sample\n",
    "    inputs = self.slope*inputs + self.bias # ax + b 계산하기 => 이와 같이 외부로 부터 받아야 하는 값이 필요할 때에는 __init__ 이 필요하다.\n",
    "\n",
    "    return inputs, labels \n",
    "  \n",
    "  # .....\n",
    "  # 추가로 계속 원하는 전처리를 정의 할 수 있다.\n",
    "  # ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = tr.Compose([ToTensor(), LinearTensor(2, 5)]) # 텐서 변환 후 선형식 2x+5 연산\n",
    "dataset1 = MyDataset(train_images, train_labels, transform=trans) \n",
    "train_loader1 = DataLoader(dataset1, batch_size=10, shuffle=True)\n",
    "\n",
    "# ToTensor()와 tr.ToTensor()의 차이\n",
    "# 앞서 사용한 tr.ToTensor()는 import torchvision.transform as tr를 이용한 파이토치 메소드를 이용한 것이고\n",
    "# ToTensor()는 위에서 정의 된 메서드를 사용한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "data_iter1 = iter(train_loader1)\n",
    "images1, labels1 = next(data_iter1)\n",
    "\n",
    "print(images1.size()) # 배치 및 이미지 크기 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 커스텀 데이터 + torchvision.transforms 전처리\n",
    "\n",
    "PyTorch로 이미지 데이터를 학습할 준비를 하는 과정으로,\n",
    "넘파이 이미지 데이터를 Pytorch가 이해 할 수 있도록 전처리하고, DataLoader로 배치 단위로 불러오는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.transforms에서 제공하는 전처리 기술을 사용한다.\n",
    "# torchvision.transforms은 입력 이미지가 일반적으로 PILImage 타입이나 텐서일 경우에 동작한다.\n",
    "# 현재 데이터는 넘파이 배열이다. 따라서 텐서 변환 후 tr.ToPILImage()을 이용하여 PILImage 타입으로 만들어 준다.\n",
    "# __call__을 이용한 기본 구조는 동일하다.\n",
    "\n",
    "# 이미지 전처리기\n",
    "# __call__을 정의했기 때문에 함수처럼 작동한다.\n",
    "class MyTransform:\n",
    "  def __call__(self, sample):\n",
    "    inputs, labels = sample\n",
    "    inputs = torch.FloatTensor(inputs)\n",
    "    inputs = inputs.permute(2, 0, 1)\n",
    "    labels = torch.FloatTensor(labels)\n",
    "\n",
    "    transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor(), tr.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    final_output = transf(inputs)\n",
    "\n",
    "    return final_output, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = MyDataset(train_images, train_labels, transform=MyTransform())\n",
    "train_loader2 = DataLoader(dataset2, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "data_iter2 = iter(train_loader2)\n",
    "images2, label2 = next(data_iter2)\n",
    "\n",
    "print(images2.size()) # 배치 및 이미지 크기 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
